{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42922fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import product\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f1b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand Size\n",
    "demand_size_list = [i for i in range(100, 601, 50)]\n",
    "# Demand Split Ratio (Intra Modal, %)\n",
    "demand_split_ratio_list = [i for i in range(10, 91, 20)]\n",
    "\n",
    "# Random Seed\n",
    "random_seed_list = [3, 6, 9]\n",
    "\n",
    "# Network Name\n",
    "network_name = \"11-500\"\n",
    "\n",
    "# Walking Speed (m/s)\n",
    "WALKING_SPEED = 1.33\n",
    "\n",
    "# PT Network Name list\n",
    "pt_network_name_list = [\"basic\", \"ring\", \"diagonal\", \"mature\"]\n",
    "\n",
    "# Demand File Directory\n",
    "demand_dir = f\"data/demand/{network_name}/total/\"\n",
    "\n",
    "# Output Directory\n",
    "output_dir = f\"data/demand/{network_name}/pt/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e0d5a",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29bfbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 242\n",
      "Number of left nodes: 121\n",
      "Number of right nodes: 121\n"
     ]
    }
   ],
   "source": [
    "# Load Network Files\n",
    "network_name = \"11-500\"\n",
    "network_path = f\"data/network/{network_name}/\"\n",
    "node_df = pd.read_csv(network_path + \"nodes.csv\")\n",
    "link_df = pd.read_csv(network_path + \"edges.csv\")\n",
    "\n",
    "node_id_list = node_df['node_index'].tolist()\n",
    "print(f\"Number of nodes: {len(node_id_list)}\")\n",
    "\n",
    "left_node_id_list = [i for i in range(0, len(node_id_list)//2)]\n",
    "right_node_id_list = [i for i in range(len(node_id_list)//2, len(node_id_list))]\n",
    "print(f\"Number of left nodes: {len(left_node_id_list)}\")\n",
    "print(f\"Number of right nodes: {len(right_node_id_list)}\")\n",
    "\n",
    "left_mobility_node_id_list = [116, 117, 118, 119, 120]\n",
    "right_mobility_node_id_list = [237, 238, 239, 240, 241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bee2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (242, 242)\n"
     ]
    }
   ],
   "source": [
    "# Load Distance Matrix\n",
    "distance_matrix = np.load(network_path + \"dist_matrix.npy\")\n",
    "print(f\"Distance matrix shape: {distance_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ddfb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel time matrix shape: (242, 242)\n"
     ]
    }
   ],
   "source": [
    "# Load Travel Time Matrix\n",
    "tt_matrix = np.load(network_path + \"tt_matrix.npy\")\n",
    "print(f\"Travel time matrix shape: {tt_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069491da",
   "metadata": {},
   "source": [
    "# PT GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea8d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_station_ids(stop_times_filepath):\n",
    "    stop_times_df = pd.read_csv(stop_times_filepath)\n",
    "    stop_id_list = stop_times_df['stop_id'].unique().tolist()\n",
    "    # Get station id from stop id: 54-1 -> 54\n",
    "    station_id_list = [stop_id.split('-')[0] for stop_id in stop_id_list]\n",
    "    # Remove duplicates\n",
    "    station_id_list = list(set(station_id_list))\n",
    "    # Replace A and B with 120, 241\n",
    "    station_id_list = [120 if stop_id == 'A' else 241 if stop_id == 'B' else stop_id for stop_id in station_id_list]\n",
    "    # Convert to int and sort\n",
    "    station_id_list = sorted([int(stop_id) for stop_id in station_id_list])\n",
    "    return station_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "240e8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_station(node_id, station_id_list, distance_matrix, walking_speed):\n",
    "    \"\"\"Find the nearest station to the given node_id from the station_id_list.\n",
    "    If multiple stations are at the same distance, return all.\n",
    "    \"\"\"\n",
    "    min_distance = float('inf')\n",
    "    nearest_station_ids = []\n",
    "    # Find the minimum distance\n",
    "    for station_id in station_id_list:\n",
    "        dist = distance_matrix[node_id][station_id]\n",
    "        if dist < min_distance:\n",
    "            min_distance = dist\n",
    "    # Find all stations with the min_distance\n",
    "    for station_id in station_id_list:\n",
    "        if distance_matrix[node_id][station_id] == min_distance:\n",
    "            nearest_station_ids.append(station_id)\n",
    "\n",
    "    travel_time_in_seconds = int(min_distance / walking_speed)  # in seconds\n",
    "    return nearest_station_ids, min_distance, travel_time_in_seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768e364",
   "metadata": {},
   "source": [
    "# Create PT Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379d126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT Network: basic, Number of stations: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:06<00:00, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT Network: ring, Number of stations: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:06<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT Network: diagonal, Number of stations: 114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:07<00:00, 22.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT Network: mature, Number of stations: 138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:08<00:00, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scenarios processed: 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "all_demand_combinations = list(product(demand_size_list, demand_split_ratio_list, random_seed_list))\n",
    "\n",
    "for pt_network_name in pt_network_name_list:\n",
    "    # Find all station ids for the PT network\n",
    "    stop_times_filepath = f'data/GTFS/pt/{pt_network_name}_pt_train-10_bus-10/stop_times_fp.txt'\n",
    "    station_id_list = find_all_station_ids(stop_times_filepath)\n",
    "    print(f\"PT Network: {pt_network_name}, Number of stations: {len(station_id_list)}\")\n",
    "\n",
    "    # Create PT Demand Save Directory\n",
    "    pt_demand_output_dir = os.path.join(output_dir, pt_network_name)\n",
    "    os.makedirs(pt_demand_output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each demand file\n",
    "    for demand_size, demand_split_ratio, random_seed in tqdm(all_demand_combinations):\n",
    "        demand_filepath = os.path.join(demand_dir, f\"ds{demand_size}_dsr{demand_split_ratio}_rs{random_seed}.csv\")\n",
    "        demand_df = pd.read_csv(demand_filepath)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        # Add New Columns\n",
    "        demand_df['start_station_ids'] = ''\n",
    "        demand_df['end_station_ids'] = ''\n",
    "        \n",
    "        demand_df['walk_start_to_station_distance'] = 0\n",
    "        demand_df['walk_start_to_station_tt'] = 0\n",
    "        \n",
    "        demand_df['walk_station_to_end_distance'] = 0\n",
    "        demand_df['walk_station_to_end_tt'] = 0\n",
    "        \n",
    "        demand_df['station_departure_time'] = 0\n",
    "\n",
    "        # Process each demand record\n",
    "        for index, row in demand_df.iterrows():\n",
    "            start_node_id = row['start']\n",
    "            end_node_id = row['end']\n",
    "            rq_time = row['rq_time']\n",
    "\n",
    "            # Find nearest station for start node\n",
    "            start_station_ids, start_distance, start_tt = find_nearest_station(start_node_id, station_id_list, distance_matrix, WALKING_SPEED)\n",
    "            # Find nearest station for end node\n",
    "            end_station_ids, end_distance, end_tt = find_nearest_station(end_node_id, station_id_list, distance_matrix, WALKING_SPEED)\n",
    "\n",
    "            # Update demand record\n",
    "            demand_df.at[index, 'start_station_ids'] = str(start_station_ids).replace(\",\", \";\")\n",
    "            demand_df.at[index, 'end_station_ids'] = str(end_station_ids).replace(\",\", \";\")\n",
    "            \n",
    "            demand_df.at[index, 'walk_start_to_station_distance'] = start_distance\n",
    "            demand_df.at[index, 'walk_start_to_station_tt'] = start_tt\n",
    "            \n",
    "            demand_df.at[index, 'walk_station_to_end_distance'] = end_distance\n",
    "            demand_df.at[index, 'walk_station_to_end_tt'] = end_tt\n",
    "\n",
    "            demand_df.at[index, 'station_departure_time'] = start_tt + rq_time\n",
    "\n",
    "        # Save the new demand file\n",
    "        output_filepath = os.path.join(pt_demand_output_dir, f\"pt_ds{demand_size}_dsr{demand_split_ratio}_rs{random_seed}.csv\")\n",
    "        demand_df.to_csv(output_filepath, index=False)\n",
    "\n",
    "print(f\"Total scenarios processed: {counter}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
