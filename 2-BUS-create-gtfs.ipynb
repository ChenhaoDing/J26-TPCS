{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db17ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce7538",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2330e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUS Network\n",
    "bus_network_list = ['basic', 'diagonal', 'ring', 'mature']\n",
    "# Train Headway (min)\n",
    "train_headway_list = [i for i in range(10, 31, 5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768b519",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93819cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 242\n",
      "Number of left nodes: 121\n",
      "Number of right nodes: 121\n"
     ]
    }
   ],
   "source": [
    "# Load Network Files\n",
    "network_name = \"11-500\"\n",
    "network_path = f\"data/network/{network_name}/\"\n",
    "node_df = pd.read_csv(network_path + \"nodes.csv\")\n",
    "link_df = pd.read_csv(network_path + \"edges.csv\")\n",
    "\n",
    "node_id_list = node_df['node_index'].tolist()\n",
    "print(f\"Number of nodes: {len(node_id_list)}\")\n",
    "\n",
    "left_node_id_list = [i for i in range(0, len(node_id_list)//2)]\n",
    "right_node_id_list = [i for i in range(len(node_id_list)//2, len(node_id_list))]\n",
    "print(f\"Number of left nodes: {len(left_node_id_list)}\")\n",
    "print(f\"Number of right nodes: {len(right_node_id_list)}\")\n",
    "\n",
    "left_mobility_node_id_list = [116, 117, 118, 119, 120]\n",
    "right_mobility_node_id_list = [237, 238, 239, 240, 241]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2e6672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance matrix shape: (242, 242)\n"
     ]
    }
   ],
   "source": [
    "# Load Distance Matrix\n",
    "distance_matrix = np.load(network_path + \"dist_matrix.npy\")\n",
    "print(f\"Distance matrix shape: {distance_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "653968b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel time matrix shape: (242, 242)\n"
     ]
    }
   ],
   "source": [
    "# Load Travel Time Matrix\n",
    "tt_matrix = np.load(network_path + \"tt_matrix.npy\")\n",
    "print(f\"Travel time matrix shape: {tt_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efd1c6",
   "metadata": {},
   "source": [
    "# Create General Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95986253",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_output_path = \"data/gtfs/general/\"\n",
    "if not os.path.exists(general_output_path):\n",
    "    os.makedirs(general_output_path)\n",
    "\n",
    "# Create stations_fp.csv\n",
    "stations_fp_df = pd.DataFrame(columns=['station_id','station_name','station_lat','station_lon','stops_included','station_stop_transfer_times','num_stops_included'])\n",
    "for index, node in node_df.iterrows():\n",
    "    station_id = node['node_index']\n",
    "    station_name = station_id\n",
    "    station_lat = node['pos_y']\n",
    "    station_lon = node['pos_x']\n",
    "\n",
    "    stops_included = \"['{}-0';'{}-1';'{}-2';'{}-3';'{}-4';'{}-5']\".format(station_id, station_id, station_id, station_id, station_id, station_id)\n",
    "    station_stop_transfer_times = '[0;0;0;0;0;0]'\n",
    "    num_stops_included = 6\n",
    "\n",
    "    new_row = pd.DataFrame({\n",
    "        'station_id': [station_id],\n",
    "        'station_name': [station_name],\n",
    "        'station_lat': [station_lat],\n",
    "        'station_lon': [station_lon],\n",
    "        'stops_included': [stops_included],\n",
    "        'station_stop_transfer_times': [station_stop_transfer_times],\n",
    "        'num_stops_included': [num_stops_included]\n",
    "    })\n",
    "\n",
    "    stations_fp_df = pd.concat([stations_fp_df, new_row], ignore_index=True)\n",
    "\n",
    "# Remove non-stop nodes\n",
    "left_non_stops_node_id_list = [1,2,3,4,6,7,8,13,14,15,17,18,21,22,31,32,33,34,37,42,43,44,45,50,52,53,62,63,65,70,71,72,73,78,81,82,83,84,93,94,97,98,100,101,102,107,108,109,111,112,113,114]\n",
    "right_non_stops_node_id_list = [i + 121 for i in left_non_stops_node_id_list]\n",
    "non_stop_node_id_list = left_non_stops_node_id_list + right_non_stops_node_id_list\n",
    "\n",
    "stations_fp_df = stations_fp_df[~stations_fp_df['station_id'].isin(non_stop_node_id_list)].reset_index(drop=True)\n",
    "\n",
    "# Change 120 to A, 241 to B\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 120, 'station_id'] = 'A'\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 'A', 'station_name'] = 'A Hub'\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 'A', 'stops_included'] = \"['A-0';'A-1';'A-2';'A-3';'A-4';'A-5']\"\n",
    "\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 241, 'station_id'] = 'B'\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 'B', 'station_name'] = 'B Hub'\n",
    "stations_fp_df.loc[stations_fp_df['station_id'] == 'B', 'stops_included'] = \"['B-0';'B-1';'B-2';'B-3';'B-4';'B-5']\"\n",
    "\n",
    "# Save stations_fp.txt\n",
    "stations_fp_df.to_csv(general_output_path + \"stations_fp.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727bf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stops_fp.txt\n",
    "stops_fp_df = pd.DataFrame(columns=['stop_id'])\n",
    "for index, row in stations_fp_df.iterrows():\n",
    "    # Convert stops_included string to list\n",
    "    s = row['stops_included']\n",
    "    if isinstance(s, str):\n",
    "        s_clean = s.strip()\n",
    "        if s_clean.startswith('[') and s_clean.endswith(']'):\n",
    "            s_clean = s_clean[1:-1]\n",
    "        s_clean = s_clean.replace(\"'\", \"\").replace('\"', '').strip()\n",
    "        if ';' in s_clean:\n",
    "            parts = [p.strip() for p in s_clean.split(';') if p.strip()]\n",
    "        elif ',' in s_clean:\n",
    "            parts = [p.strip() for p in s_clean.split(',') if p.strip()]\n",
    "        elif s_clean == '':\n",
    "            parts = []\n",
    "        else:\n",
    "            parts = [s_clean]\n",
    "    else:\n",
    "        parts = list(s) if hasattr(s, '__iter__') and not isinstance(s, str) else [s]\n",
    "    row['stops_included'] = ';'.join(parts)\n",
    "    stop_ids = row['stops_included']\n",
    "    for stop_id in stop_ids.split(';'):\n",
    "        stops_fp_df = pd.concat([stops_fp_df, pd.DataFrame({'stop_id': [stop_id]})], ignore_index=True)\n",
    "stops_fp_df.to_csv(os.path.join(general_output_path, \"stops_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f51ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare agency_fp.txt\n",
    "agency_df = pd.DataFrame({\n",
    "    'agency_id': [0, 1, 2, 3],\n",
    "    'agency_name': ['intercity-express', 'bus-basic', 'bus-ring', 'bus-diagonal'],\n",
    "})\n",
    "agency_df.to_csv(os.path.join(general_output_path, \"agency_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef9be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create calendar_fp.txt\n",
    "calendar_df = pd.DataFrame({\n",
    "    'service_id': [0],\n",
    "    'start_date': [20000101],\n",
    "    'end_date': [20991231],\n",
    "    'monday': [1],\n",
    "    'tuesday': [1],\n",
    "    'wednesday': [1],\n",
    "    'thursday': [1],\n",
    "    'friday': [1],\n",
    "    'saturday': [1],\n",
    "    'sunday': [1],\n",
    "})\n",
    "calendar_df.to_csv(os.path.join(general_output_path, \"calendar_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6a62695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create street_station_transfers_fp.txt\n",
    "all_station_ids = stations_fp_df['station_id'].tolist()\n",
    "\n",
    "street_station_transfers_fp_df = pd.DataFrame({\n",
    "    'node_id': all_station_ids,\n",
    "    'closest_station_id': all_station_ids,\n",
    "    'street_station_transfer_time': 60\n",
    "})\n",
    "\n",
    "# Change node id from A and B back to 120 and 241\n",
    "street_station_transfers_fp_df.loc[street_station_transfers_fp_df['node_id'] == 'A', 'node_id'] = 120\n",
    "street_station_transfers_fp_df.loc[street_station_transfers_fp_df['node_id'] == 'B', 'node_id'] = 241\n",
    "\n",
    "street_station_transfers_fp_df.to_csv(os.path.join(general_output_path, \"street_station_transfers_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b3587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transfers_fp.txt\n",
    "# For each station, the transfer time between its stops is 30 seconds\n",
    "transfers_fp_df = pd.DataFrame(columns=['from_stop_id', 'to_stop_id', 'min_transfer_time'])\n",
    "for index, row in stations_fp_df.iterrows():\n",
    "    stops_included = row['stops_included'].split(';')\n",
    "    for i in range(len(stops_included)):\n",
    "        for j in range(len(stops_included)):\n",
    "            if i != j:\n",
    "                new_row = pd.DataFrame({\n",
    "                    'from_stop_id': [stops_included[i]],\n",
    "                    'to_stop_id': [stops_included[j]],\n",
    "                    'min_transfer_time': [30]\n",
    "                })\n",
    "                transfers_fp_df = pd.concat([transfers_fp_df, new_row], ignore_index=True)\n",
    "transfers_fp_df.to_csv(os.path.join(general_output_path, \"transfers_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59715d4f",
   "metadata": {},
   "source": [
    "# Create GTFS for Basic Bus Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9681c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_timetable(base_trip_data, study_start_str, study_end_str, headway_minutes):\n",
    "    \"\"\"\n",
    "    扩展单个基准行程的时刻表。\n",
    "\n",
    "    参数:\n",
    "    - base_trip_data (dict): 包含基准行程信息的字典。\n",
    "    - study_start_str (str): 研究范围的开始时间 (HH:MM:SS)。\n",
    "    - study_end_str (str): 研究范围的结束时间 (HH:MM:SS)。\n",
    "    - headway_minutes (int): 发车间隔（分钟）。\n",
    "\n",
    "    返回:\n",
    "    - pd.DataFrame: 包含所有扩展行程的 DataFrame。\n",
    "    \"\"\"\n",
    "    # 将时间字符串转换为 datetime 对象以便计算\n",
    "    study_start_time = datetime.strptime(study_start_str, '%H:%M:%S')\n",
    "    study_end_time = datetime.strptime(study_end_str, '%H:%M:%S')\n",
    "    headway = timedelta(minutes=headway_minutes)\n",
    "\n",
    "    # 将基准行程字典转换为 DataFrame\n",
    "    base_df = pd.DataFrame(base_trip_data)\n",
    "    \n",
    "    # 将 DataFrame 中的时间字符串转换为 datetime 对象\n",
    "    base_df['arrival_time'] = pd.to_datetime(base_df['arrival_time'], format='%H:%M:%S')\n",
    "    base_df['departure_time'] = pd.to_datetime(base_df['departure_time'], format='%H:%M:%S')\n",
    "\n",
    "    all_trips = [base_df]\n",
    "    base_trip_id = base_df['trip_id'].iloc[0]\n",
    "\n",
    "    # --- 向前扩展行程 ---\n",
    "    current_trip_df = base_df.copy()\n",
    "    counter = 1\n",
    "    while True:\n",
    "        next_trip_df = current_trip_df.copy()\n",
    "        # 增加 headway 时间\n",
    "        next_trip_df['arrival_time'] += headway\n",
    "        next_trip_df['departure_time'] += headway\n",
    "        \n",
    "        # 检查新行程的开始时间是否在研究范围内\n",
    "        if next_trip_df['departure_time'].iloc[0] >= study_end_time:\n",
    "            break\n",
    "            \n",
    "        # 更新 trip_id\n",
    "        next_trip_df['trip_id'] = f\"{base_trip_id}-{counter}\"\n",
    "        all_trips.append(next_trip_df)\n",
    "        \n",
    "        current_trip_df = next_trip_df\n",
    "        counter += 1\n",
    "\n",
    "    # --- 向后扩展行程 ---\n",
    "    current_trip_df = base_df.copy()\n",
    "    while True:\n",
    "        prev_trip_df = current_trip_df.copy()\n",
    "        # 减去 headway 时间\n",
    "        prev_trip_df['arrival_time'] -= headway\n",
    "        prev_trip_df['departure_time'] -= headway\n",
    "\n",
    "        # 检查新行程的开始时间是否在研究范围内\n",
    "        if prev_trip_df['departure_time'].iloc[0] < study_start_time:\n",
    "            break\n",
    "\n",
    "        # 更新 trip_id\n",
    "        prev_trip_df['trip_id'] = f\"{base_trip_id}-{counter}\"\n",
    "        # 将向后生成的行程插入到列表的开头，以保持时间顺序\n",
    "        all_trips.insert(0, prev_trip_df)\n",
    "        \n",
    "        current_trip_df = prev_trip_df\n",
    "        counter += 1\n",
    "        \n",
    "    # 合并这个基准线路产生的所有行程\n",
    "    expanded_df = pd.concat(all_trips, ignore_index=True)\n",
    "\n",
    "    # Add 0 to trip_id for base trip\n",
    "    expanded_df.loc[expanded_df['trip_id'] == base_trip_id, 'trip_id'] = f\"{base_trip_id}-0\"\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUS_HEADWAY = 10\n",
    "STUDY_START = \"00:00:00\"\n",
    "STUDY_END = \"08:00:00\"\n",
    "\n",
    "# Prepare output path\n",
    "basic_output_path = f\"data/gtfs/bus/basic/bus_headway_{BUS_HEADWAY}/\"\n",
    "if not os.path.exists(basic_output_path):\n",
    "    os.makedirs(basic_output_path)\n",
    "\n",
    "# Create routes_fp.txt\n",
    "routes_df = pd.DataFrame({\n",
    "    'route_id': [1, 2, 3, 4],\n",
    "    'route_short_name': ['bus-basic-we-left', 'bus-basic-ns-left', 'bus-basic-we-right', 'bus-basic-ns-right'],\n",
    "    'route_desc': ['bus', 'bus', 'bus', 'bus'],\n",
    "})\n",
    "routes_df.to_csv(os.path.join(basic_output_path, \"routes_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "381e8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stop_times_fp.txt\n",
    "# Use 10 minute headway\n",
    "stop_times_fp_df = pd.DataFrame(columns=['trip_id', 'arrival_time', 'departure_time', 'stop_id', 'stop_sequence'])\n",
    "\n",
    "# For w-e direction in the left side\n",
    "we_left_base_trip_times_0 = {\n",
    "    'trip_id': '1-0', # route_id-direction\n",
    "    'stop_id': ['54-1', '55-1', '56-1', '57-1', '117-1', '120-1', '118-1', '58-1', '59-1', '60-1', '61-1'],\n",
    "    'arrival_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'departure_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'stop_sequence': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "we_left_base_trip_times_1 = {\n",
    "    'trip_id': '1-1', # route_id-direction\n",
    "    'stop_id': ['54-1', '55-1', '56-1', '57-1', '117-1', '120-1', '118-1', '58-1', '59-1', '60-1', '61-1'],\n",
    "    'arrival_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'departure_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'stop_sequence': [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "ns_left_base_trip_times_0 = {\n",
    "    'trip_id': '2-0', # route_id-direction\n",
    "    'stop_id': ['110-2', '99-2', '88-2', '77-2', '119-2', '120-2', '116-2', '38-2', '27-2', '16-2', '5-2'],\n",
    "    'arrival_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'departure_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'stop_sequence': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "ns_left_base_trip_times_1 = {\n",
    "    'trip_id': '2-1', # route_id-direction\n",
    "    'stop_id': ['110-2', '99-2', '88-2', '77-2', '119-2', '120-2', '116-2', '38-2', '27-2', '16-2', '5-2'],\n",
    "    'arrival_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'departure_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'stop_sequence': [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "we_right_base_trip_times_0 = {\n",
    "    'trip_id': '3-0', # route_id-direction\n",
    "    'stop_id': ['175-1', '176-1', '177-1', '178-1', '238-1', '241-1', '239-1', '179-1', '180-1', '181-1', '182-1'],\n",
    "    'arrival_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'departure_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'stop_sequence': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "we_right_base_trip_times_1 = {\n",
    "    'trip_id': '3-1', # route_id-direction\n",
    "    'stop_id': ['175-1', '176-1', '177-1', '178-1', '238-1', '241-1', '239-1', '179-1', '180-1', '181-1', '182-1'],\n",
    "    'arrival_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'departure_time': ['00:54:30', '00:56:00', '00:57:30', '00:59:00', '01:00:30', '01:02:00', '01:03:30', '01:05:00', '01:06:30', '01:08:00', '01:09:30'],\n",
    "    'stop_sequence': [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "ns_right_base_trip_times_0 = {\n",
    "    'trip_id': '4-0', # route_id-direction\n",
    "    'stop_id': ['231-2', '220-2', '209-2', '198-2', '240-2', '241-2', '237-2', '159-2', '148-2', '137-2', '126-2'],\n",
    "    'arrival_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'departure_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'stop_sequence': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "ns_right_base_trip_times_1 = {\n",
    "    'trip_id': '4-1', # route_id-direction\n",
    "    'stop_id': ['231-2', '220-2', '209-2', '198-2', '240-2', '241-2', '237-2', '159-2', '148-2', '137-2', '126-2'],\n",
    "    'arrival_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'departure_time': ['00:59:30', '01:01:00', '01:02:30', '01:04:00', '01:05:30', '01:07:00', '01:08:30', '01:10:00', '01:11:30', '01:13:00', '01:14:30'],\n",
    "    'stop_sequence': [11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "}\n",
    "\n",
    "# Use headway to create multiple trips for the study period: 00:00:00 to 08:00:00\n",
    "base_schedules = [we_left_base_trip_times_0,\n",
    "                    we_left_base_trip_times_1,\n",
    "                    ns_left_base_trip_times_0,\n",
    "                    ns_left_base_trip_times_1,\n",
    "                    we_right_base_trip_times_0,\n",
    "                    we_right_base_trip_times_1,\n",
    "                    ns_right_base_trip_times_0,\n",
    "                    ns_right_base_trip_times_1]\n",
    "\n",
    "all_schedules_list = []\n",
    "for schedule_data in base_schedules:\n",
    "    expanded_schedule = expand_timetable(schedule_data, STUDY_START, STUDY_END, BUS_HEADWAY)\n",
    "    all_schedules_list.append(expanded_schedule)\n",
    "\n",
    "final_timetable = pd.concat(all_schedules_list, ignore_index=True)\n",
    "\n",
    "final_timetable['arrival_time'] = final_timetable['arrival_time'].dt.strftime('%H:%M:%S')\n",
    "final_timetable['departure_time'] = final_timetable['departure_time'].dt.strftime('%H:%M:%S')\n",
    "\n",
    "stop_times_fp_df = final_timetable\n",
    "stop_times_fp_df.to_csv(os.path.join(basic_output_path, \"stop_times_fp.txt\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22749ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trips_fp.txt\n",
    "trips_fp_df = pd.DataFrame(columns=['trip_id','route_id','service_id','direction_id'])\n",
    "\n",
    "all_trip_ids = final_timetable['trip_id'].unique().tolist()\n",
    "for trip_id in all_trip_ids:\n",
    "    route_id = int(trip_id.split('-')[0])\n",
    "    direction_id = int(trip_id.split('-')[1])\n",
    "    new_row = pd.DataFrame({\n",
    "        'trip_id': [trip_id],\n",
    "        'route_id': [route_id],\n",
    "        'service_id': [0],\n",
    "        'direction_id': [direction_id]\n",
    "    })\n",
    "    trips_fp_df = pd.concat([trips_fp_df, new_row], ignore_index=True)\n",
    "\n",
    "trips_fp_df.to_csv(os.path.join(basic_output_path, \"trips_fp.txt\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
